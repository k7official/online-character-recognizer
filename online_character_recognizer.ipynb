{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75658823-d208-4b84-a581-a6d4451b77c8",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "In this competition, you are given a dataset containing the handwritten trajectories of numerals, each with eight $x-y$ coordinates. You must design a recurrent network to recognize the trajectories into their corresponding numerals.\n",
    "\n",
    "\n",
    "### Descriptions:\n",
    "* $A$: an RNN cell (or LSTM or GRU cell) which contains $N_h$ hidden neurons inside;\n",
    "* $O$: the output layer containing 10 neurons to output the predicted likelihood of the 10 numerals. Find the one with the largest likelihood as the recognition numeral; In this problem, we only need to output the recognized numeral at the time step that all of the eight coordinates are received, that is the $8^{th}$ time step. Therefore, it is unnecessary to output the intermediate results during the first seven time steps;\n",
    "* $W_y$: the hidden-to-output connection weight matrix;\n",
    "* Loss function: you can use the cross-entropy to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8111e6-9531-4428-950a-5d93636da262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d999aa-d507-4017-9339-f47652ff3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f6d9174-23f8-4ed1-a059-0f91f97a7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 2  # Adjusted to match the number of coordinates (x, y)\n",
    "sequence_length = 8  # Adjusted to match the number of coordinates in each trajectory\n",
    "hidden_size = 512  # Adjusted to increase the number of hidden neurons\n",
    "num_layers = 3  # Adjusted to increase the number of layers\n",
    "dropout_prob = 0.5 # Adjusted to randomly drop out 50% of the input units during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0064e8-2bfe-4ebb-9e12-9492c0080501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = \"train_in.csv\"\n",
    "train_out = \"train_out.csv\"\n",
    "test_in = \"test_in.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280addb2-15d1-4544-a2f1-1fa3632322d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y=None):\n",
    "        # read with numpy\n",
    "        x = np.loadtxt(x, delimiter=',', dtype=np.float32, skiprows=1)  # Change dtype to float32\n",
    "        if y is not None:\n",
    "            y = np.loadtxt(y, delimiter=',', dtype=np.float32, skiprows=1)  # Change dtype to float32\n",
    "        self.n_samples = x.shape[0]\n",
    "\n",
    "        # here the first column is the serial no, the rest are the feature coordinates\n",
    "        self.x_data = torch.from_numpy(x[:, 1:])  # Convert to torch.float32\n",
    "        if y is not None:\n",
    "            self.y_data = torch.from_numpy(y[:, [1]])  # Convert to torch.float32\n",
    "        else:\n",
    "            self.y_data = None\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        if self.y_data is not None and len(self.y_data) > 0:\n",
    "            return self.x_data[index], self.y_data[index]\n",
    "        else:\n",
    "            return self.x_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72d5ede8-48bc-4616-a150-31c50376fbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 47., 100.,  27.,  81.,  57.,  37.,  26.,   0.,   0.,  23.,  56.,  53.,\n",
      "        100.,  90.,  40.,  98.]) tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "# create Dataset\n",
    "train_dataset = CustomDataset(train_in, train_out)\n",
    "test_dataset = CustomDataset(test_in)\n",
    "\n",
    "# get first sample and unpack\n",
    "\n",
    "first_data = train_dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8950884e-a30b-4276-8f25-7ee7f5b987c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3edc1b54-e78b-4f3d-b1d7-ea26058c0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d380ca-e0e5-48d2-82bc-3ab1c716255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 24\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "total_samples = len(train_loader)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dee507-a9f6-46fe-8f8a-aee52c86d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1032ec44-ad28-45c7-9248-55a9ea8d038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        # self.activation = nn.ReLU()  # Add an activation function (e.g., ReLU)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        # c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.gru(x, h0)  \n",
    "        # or:\n",
    "        # out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        # out = self.activation(out)  # Apply the activation function to the output\n",
    "        # out: (n, 10)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ded2e-1609-4723-af72-a93582b9ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.activation = nn.ReLU()  # Add an activation function (e.g., ReLU)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        out = self.activation(out)  # Apply the activation function to the output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb779afd-13cf-474f-b61d-aa017b73a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes, dropout_prob).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e695b9be-ca57-4b4e-b863-57a06df77697",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [64/94], Loss: 0.1398\n",
      "Epoch [1/10], Loss: 0.1640\n",
      "Epoch [1/10], Validation Loss: 0.1492, Validation Accuracy: 94.86%\n",
      "Epoch [2/10], Step [64/94], Loss: 0.0628\n",
      "Epoch [2/10], Loss: 0.0549\n",
      "Epoch [2/10], Validation Loss: 0.0455, Validation Accuracy: 98.47%\n",
      "Epoch [3/10], Step [64/94], Loss: 0.0128\n",
      "Epoch [3/10], Loss: 0.0097\n",
      "Epoch [3/10], Validation Loss: 0.0436, Validation Accuracy: 98.53%\n",
      "Epoch [4/10], Step [64/94], Loss: 0.0119\n",
      "Epoch [4/10], Loss: 0.0117\n",
      "Epoch [4/10], Validation Loss: 0.0817, Validation Accuracy: 97.20%\n",
      "Epoch [5/10], Step [64/94], Loss: 0.0587\n",
      "Epoch [5/10], Loss: 0.0194\n",
      "Epoch [5/10], Validation Loss: 0.0838, Validation Accuracy: 98.07%\n",
      "Epoch [6/10], Step [64/94], Loss: 0.0348\n",
      "Epoch [6/10], Loss: 0.0021\n",
      "Epoch [6/10], Validation Loss: 0.0297, Validation Accuracy: 99.27%\n",
      "Epoch [7/10], Step [64/94], Loss: 0.1861\n",
      "Epoch [7/10], Loss: 0.0048\n",
      "Epoch [7/10], Validation Loss: 0.0555, Validation Accuracy: 98.27%\n",
      "Epoch [8/10], Step [64/94], Loss: 0.0099\n",
      "Epoch [8/10], Loss: 0.0334\n",
      "Epoch [8/10], Validation Loss: 0.0497, Validation Accuracy: 98.73%\n",
      "Epoch [9/10], Step [64/94], Loss: 0.0832\n",
      "Epoch [9/10], Loss: 0.0005\n",
      "Epoch [9/10], Validation Loss: 0.0263, Validation Accuracy: 99.27%\n",
      "Epoch [10/10], Step [64/94], Loss: 0.0750\n",
      "Epoch [10/10], Loss: 0.0018\n",
      "Epoch [10/10], Validation Loss: 0.0322, Validation Accuracy: 99.20%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        # Reshape input data\n",
    "        features = features.view(-1, sequence_length, input_size)\n",
    "        \n",
    "        # Convert labels to indices and apply one-hot encoding\n",
    "        labels_indices = torch.squeeze(labels).long()\n",
    "        labels_one_hot = torch.eye(num_classes)[labels_indices]\n",
    "\n",
    "        # Forward pass, backward pass, and optimization\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training progress\n",
    "        if (i+1) % 64 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    # Print epoch loss\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "        \n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for features, labels in val_loader:\n",
    "            # Reshape input data\n",
    "            features = features.view(-1, sequence_length, input_size)\n",
    "\n",
    "            # Convert labels to indices and apply one-hot encoding\n",
    "            labels_indices = torch.squeeze(labels).long()\n",
    "            labels_one_hot = torch.eye(num_classes)[labels_indices]\n",
    "\n",
    "            outputs = model(features)\n",
    "            val_loss = criterion(outputs, labels_one_hot)\n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels_indices).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print('Epoch [{}/{}], Validation Loss: {:.4f}, Validation Accuracy: {:.2f}%'\n",
    "              .format(epoch+1, num_epochs, avg_val_loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83d263db-aadc-461f-bce7-86364ed65181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017893353942781687"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c158ca0-5156-4bab-a7a2-e9d8362a4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "predictions = []\n",
    "serial_numbers = []\n",
    "serial_number = 1  # Initialize serial number\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features in test_loader:\n",
    "        # Reshape input data\n",
    "        features = features.view(-1, sequence_length, input_size)\n",
    "        features = features.to(device)\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        \n",
    "        # Add serial numbers\n",
    "        num_predictions = len(predicted)\n",
    "        serial_numbers.extend(list(range(serial_number, serial_number + num_predictions)))\n",
    "        \n",
    "        # Update serial number for the next set of predictions\n",
    "        serial_number += num_predictions\n",
    "\n",
    "# Create a DataFrame with 'Serial No.' and 'Label' columns\n",
    "output_df = pd.DataFrame({'Serial No.': serial_numbers, 'Label': predictions})\n",
    "\n",
    "# Write the predictions to the output CSV file\n",
    "output_df.to_csv('output6.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "948cd770-1ad8-4b1c-bd39-65eb6ebdb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# Model Architecture\n",
    "# Hyperparameters\n",
    "# num_classes = 10\n",
    "# num_epochs = 10\n",
    "# batch_size = 4\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# input_size = 2  # Adjusted to match the number of coordinates (x, y)\n",
    "# sequence_length = 8  # Adjusted to match the number of coordinates in each trajectory\n",
    "# hidden_size = 512  # Adjusted to increase the number of hidden neurons\n",
    "# num_layers = 5  # Adjusted to increase the number of layers\n",
    "torch.save(model.state_dict(), 'model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75138421-5ac9-48f1-9a2e-1832ce8dc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# Model Architecture\n",
    "# num_classes = 10\n",
    "# num_epochs = 10\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# input_size = 2  # Adjusted to match the number of coordinates (x, y)\n",
    "# sequence_length = 8  # Adjusted to match the number of coordinates in each trajectory\n",
    "# hidden_size = 512  # Adjusted to increase the number of hidden neurons\n",
    "# num_layers = 3  # Adjusted to increase the number of layers\n",
    "# dropout_prob = 0.5 # Adjusted to randomly drop out 50% of the input units during training\n",
    "torch.save(model.state_dict(), 'model2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
